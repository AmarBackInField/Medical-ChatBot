{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=\"AIzaSyA3KNgJIorcrjTPBYycEpoGgqPcUDKu9Us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-google\n",
      "  Downloading llama_index_embeddings_google-0.1.6-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-embeddings-google) (0.5.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-embeddings-google) (0.10.66)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.141.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.33.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.25.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.24.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.10.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.2.1)\n",
      "Requirement already satisfied: nltk>=3.8.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.40.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2.3.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (4.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.63.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.9)\n",
      "Requirement already satisfied: click in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2024.7.24)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from tqdm->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (3.21.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.2.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.65.4)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (3.1.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (24.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amarc\\onedrive\\desktop\\llm\\rag_with_gemini\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-google) (1.16.0)\n",
      "Downloading llama_index_embeddings_google-0.1.6-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: llama-index-embeddings-google\n",
      "Successfully installed llama-index-embeddings-google-0.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from IPython.display import Markdown,display\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import StorageContext,load_index_from_storage\n",
    "import google.generativeai as genai \n",
    "from llama_index.embeddings.google import GeminiEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
      "                   'model.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
      "                   'model that supports tuning.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro Latest',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro 001',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-exp-0801',\n",
      "      base_model_id='',\n",
      "      version='exp-0801',\n",
      "      display_name='Gemini 1.5 Pro Experimental 0801',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash Latest',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 001',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-001-tuning',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 001 Tuning',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=16384,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001-tuning\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  text-2-text and image-2-text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=SimpleDirectoryReader(\"../Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=documents.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.comNiki Parmar∗\n",
      "Google Research\n",
      "nikip@google.comJakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.comAidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗ ‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "†Work performed while at Google Brain.\n",
      "‡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_embed_model=GeminiEmbedding(model_name=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Gemini(models='gemini-pro',api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amarc\\AppData\\Local\\Temp\\ipykernel_22244\\44247397.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context=ServiceContext.from_defaults(llm=model,embed_model=gemini_embed_model,chunk_size=800,chunk_overlap=20)\n"
     ]
    }
   ],
   "source": [
    "service_context=ServiceContext.from_defaults(llm=model,embed_model=gemini_embed_model,chunk_size=800,chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(docs,service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x11db34349a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=query_engine.query(\"Tell me about encoder and decoder in 200 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-decoder structures are common in neural sequence transduction models. The encoder takes an input sequence of symbols and transforms it into a sequence of continuous representations. This representation captures the essence of the input sequence. The decoder then uses this representation to generate an output sequence, one element at a time. The decoder is auto-regressive, meaning it uses previously generated symbols as input when generating the next symbol. This process allows the model to learn dependencies between elements in the sequence and produce coherent outputs. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
